import operator
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel
from typing import Annotated
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, add_messages, END
from langgraph.prebuilt import ToolNode
from datetime import datetime
from langgraph.prebuilt import InjectedState

load_dotenv()

# Load the copywriter system prompt and content examples
copywriter_prompt = open("prompts/copywriter.md", "r").read()
linkedin_example = open("example_content/linkedin.md", "r").read()
blog_example = open("example_content/blog.md", "r").read()


class CopyWriterState(BaseModel):
    """The state of the copywriter agent.

    The research_reports attribute is shared with the supervisor state. This allows the supervisor to access the research reports generated by the researcher and share them with the copywriter.
    """
    messages: Annotated[list, add_messages] = []
    research_reports: Annotated[list, operator.add] = []


@tool
async def review_research_reports(
        state: Annotated[CopyWriterState, InjectedState],
):
    """Use this tool to review available research reports to inform your writing.

    Returns:
        A list of research reports.
    """
    return [report.model_dump_json() for report in state.research_reports]


@tool
async def generate_linkedin_post(
        title: str,
        content: str,
):
    """Use this tool to generate a LinkedIn post.

    Args:
        title: The title of the post.
        content: The content of the post in markdown format.

    Returns:
        A string indicating the location of the saved post.
    """
    filename = f"ai_files/{title}.md"
    with open(filename, "w") as f:
        f.write(content)

    return f"The LinkedIn post has been generated and saved to {filename}"


@tool
async def generate_blog_post(
        title: str,
        content: str,
):
    """Use this tool to generate a blog post.

    Args:
        title: The title of the post.
        content: The content of the post in markdown format.

    Returns:
        A string indicating the location of the saved post.
    """
    filename = f"ai_files/{title}.md"
    with open(filename, "w") as f:
        f.write(content)

    return f"The blog post has been generated and saved to {filename}"


llm = ChatOpenAI(
    name="CopyWriter",
    model="gpt-5-mini-2025-08-07",
    reasoning_effort="minimal",
)

tools = [
    review_research_reports,
    generate_linkedin_post,
    generate_blog_post
]
llm_with_tools = llm.bind_tools(tools)


async def copywriter(state: CopyWriterState):
    """The main copywriter agent."""
    system_prompt = SystemMessage(content=copywriter_prompt.format(
        current_datetime=datetime.now(),
        linkedin_example=linkedin_example,
        blog_example=blog_example,
    ))
    response = llm_with_tools.invoke([system_prompt] + state.messages)
    return {"messages": [response]}


async def copywriter_router(state: CopyWriterState) -> str:
    """Route to the tools node if the copywriter makes a tool call."""
    if state.messages[-1].tool_calls:
        return "tools"
    return END


builder = StateGraph(CopyWriterState)

builder.add_node(copywriter)
builder.add_node("tools", ToolNode(tools))

builder.set_entry_point("copywriter")

builder.add_conditional_edges(
    "copywriter",
    copywriter_router,
    {
        "tools": "tools",
        END: END,
    }
)
builder.add_edge("tools", "copywriter")

# Don't use a checkpointer if using as a subgraph, the parent graph's checkpointer will be inherited
graph = builder.compile()

# graph = builder.compile(checkpointer=MemorySaver())


# Visualize the graph
# from IPython.display import Image
# Image(graph.get_graph().draw_mermaid_png())